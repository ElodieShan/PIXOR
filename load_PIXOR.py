import torch
import torch.nn as nn
import numpy as np
import time
import argparse
import random
from torch.multiprocessing import Pool

import os
from tqdm import tqdm
from evaluate_model import *

class LoadPIXOR(nn.Module):
    def __init__(self, device, n_epochs_trained=1, model_dir=None, use_voxelize_density=False, use_ImageSets=True):
        super(LoadPIXOR, self).__init__()
        # load PIXOR model
        self.model = PIXOR().to(device)
        if model_dir is not None:
            model_dir += '/Models/PIXOR_Epoch_'
        else:
            model_dir = 'Models/PIXOR_Epoch_'
        self.model.load_state_dict(torch.load(model_dir + str(n_epochs_trained) + '.pt', map_location=device))
        self.model.eval() 
        print("Successfully load PIXOR net.. ")
        self.device = device


    def forward(self, batch_dict, device=None, if_raw=False):
        '''
        generated by 
            # input, label_map, image_id = loader.dataset[image_id]
            # label_map, gt_boxes_corner = loader.dataset.get_label(image_id)
        batch_dict={
            input : point clouds.
            label_map
            image_id
            gt_boxes_corner
        }
        '''
        # forward pass
        batch_predictions = self.model(batch_dict["input"].unsqueeze(0))
            
        # convert network output to numpy for further processing
        batch_predictions_np = np.transpose(batch_predictions.detach().cpu().numpy(), (0, 2, 3, 1))
        
        # get final bounding box predictions
        final_box_predictions = process_predictions(batch_predictions_np, return_boxes=True)
        
        if final_box_predictions is not None:
            point_cloud_ids = final_box_predictions[:,0]
            final_class_predictions = final_box_predictions[:,1]
            final_loc_predictions = final_box_predictions[:,2:10] # nx8 corners 
            final_bev_boxes_predictions = final_box_predictions[:,10:] # nx5 center_x\center_y\width\length\angle 
            pred_dicts = {
                "final_box_predictions": final_box_predictions,
                "batch_predictions": batch_predictions.permute([0, 2, 3, 1]),
                "cls_pred": final_class_predictions,
                "loc_pred": final_loc_predictions, 
                "bev_box_pred": final_bev_boxes_predictions, 
                # 'final_scores': scores
            }
        else:
            pred_dicts = {
                "batch_predictions": batch_predictions.permute([0, 2, 3, 1]),
                "final_box_predictions": None,
                "cls_pred": None,
                "loc_pred": None, 
                # 'final_scores': scores
            }
        batch_dict.update(pred_dicts)
        return batch_dict


if __name__ == "__main__":

    # set device
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    print("Using device", device)

    n_epochs_trained = 17
    model_dir = "output_models/20210403_ImageSets55_Ori_Model"
    use_voxelize_density = False
    use_ImageSets = True

    # create PIXOR model
    PIXOR = LoadPIXOR(device, n_epochs_trained=n_epochs_trained, model_dir=model_dir, 
                use_voxelize_density=use_voxelize_density, use_ImageSets=use_ImageSets)
    
    # create data loader
    root_dir = 'Data/'
    batch_size = 1
    data_loader = load_dataset(root=root_dir, batch_size=batch_size, device=device, test_set=True, \
            use_voxelize_density=use_voxelize_density, use_ImageSets=use_ImageSets, \
            attack_training_mode=True)
    print("Successfully get data_loader.. ")

    image_id = 10
    # voxel_point_cloud, labels, calib, training_labels = data_loader.dataset[image_id]
    # training label : np.cos(angle_rad), np.sin(angle_rad), -center_x_m+pixel_x, -center_y_m+pixel_y, np.log(width_m), np.log(length_m), label
    # for batch_id, (batch_data, batch_labels, batch_calib, training_labels) in enumerate(data_loader):
    for i in tqdm(range(10)):
        file_id = i%len(data_loader.dataset)

        voxel_point_cloud, labels, calib, training_labels = data_loader.dataset[file_id]

        gt_boxes_lidar = []
        for label in labels:
            gt_boxes_lidar.append(label.box3d_lidar)

        batch_dict = {
            "id": file_id,
            "voxel_point_cloud": voxel_point_cloud, # unsqueeze first dimension for batch
            "gt_boxes": np.array(gt_boxes_lidar),
            "cls_targets": training_labels[:, :, -1].detach().cpu().numpy(),
            "loc_targets": training_labels[:, :, :-1].detach().cpu().numpy(),
        }

        pred_dict = PIXOR(batch_dict)
        print(pred_dict.keys())
        print(file_id)
        if i > 5:
            break
    # input, label_map, image_id = model.train_loader.dataset[image_id]
    # points = model.train_loader.dataset.get_points(image_id)
    # scan = model.train_loader.dataset.get_top_view_maps(torch.from_numpy(points).to(device))

    # print("input:",input)
    # print("scan:",scan)
    # print("input:",input.shape)
    # print("scan:",scan.shape)
    # # scan = torch.from_numpy(scan)
    # print("scan==input:",(scan==input).all())

    # label_map, label_list = model.train_loader.dataset.get_label(image_id)
    # model.train_loader.dataset.reg_target_transform(label_map)
    # batch_dict = {
    #     'input': input,
    #     'label_map': label_map,
    #     'image_id': image_id,
    #     'gt_boxes_corner': np.array(label_list)
    # }
    # model(batch_dict, device=device)

